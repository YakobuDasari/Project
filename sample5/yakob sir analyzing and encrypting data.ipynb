{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINUTES OF THE DEPARTMENT ADVISORY COMMITTEE\n",
      "MEETING HELD ON 15.12.2016\n",
      "\t\tThe Department Advisory Committee Meeting of Department of Computer Science & Engineering was held on 15-12-2016 at 10:00 AM in the HoDâ€™s Cabin, II Floor, and JC-Block. Dr. Venkatesulu Dondeti, Head, CSE has chaired the meeting and the following members have attended the meeting.\n",
      "S. No\tMembers\tDesignation\tSignature\n",
      "1\tDr. Venkatesulu  Dondeti\n",
      " \tProfessor & HOD \tChairman\t\n",
      "2\tDr. Gnaneswara Rao\n",
      "\tProfessor\tMember\t\n",
      "3\tDr. K. Hemanth Kumar,  Professor\tMember\t\n",
      "4\tMr. S. V. Rama Krishna, Asst. Professor\tMember\t\n",
      "\t\t\t\n",
      "According to the feedback given by stake holders and after thorough analysis, it is consolidated and following resolutions are made.\n",
      "Agenda of the Meeting:\n",
      "\n",
      "1. Discussion on stakeholder feedback on R13 & R16 Curriculum\n",
      "2. Discussion on CO & PO attainment outcomes\n",
      "3. Actions to be initiated to address the noncompliance of Curriculum with POs \n",
      "\n",
      "Minutes of the Meeting:\n",
      "1. Dr. Venkatesulu, Chair of the meeting has informed that, as per the stakeholder's feedback old curriculum need revision and new curriculum  of UG  program should be proposed. \n",
      "\n",
      "2. The committee members have discussed on the feedback given by various stakeholders\n",
      "\n",
      "3. The committee members discussed by introducing the few of the following POs. Few actions were suggested by committee members to bridge the gap between Curriculum and POs.\n",
      "\n",
      "4. From the CO & attainment report, the Committee concluded that among all the courses, some courses mapping with substantial correlation with Program Outcomes such as Engineering Knowledge (PO1), Problem Analysis (PO2), Design/ Development of Solutions (PO3), Individual and Team Work (PO9), Communications (PO10), Life Long Learning (PO12) and the remaining Program Outcomes such as Conduct Investigations of Complex Problems (PO4), Modern Tool Usage (PO5), The Engineer & Society (PO6), Environment and Sustainability (PO7), Ethics (PO8), Project Management and Finance (PO11) with moderate correlation.\n",
      "\n",
      "\n",
      "\n",
      "Suggestions:\n",
      "\n",
      "1.\tConsistent up-gradation of the course curriculum in-line with the industry and society needs.\n",
      "2.\tIntegrate the courses with laboratories and minor projects to enrich problem-solving skills.\n",
      "3.\tInvolve the Industry and Research personnel in Course Curriculum Development, Course Evaluation, and Feedback to enhance the quality of the curriculum.\n",
      "4.\tInclusion of Employability and Life Skills (Extension Activities, Gardening, Yoga, etc.) as Credit Courses to realize the needs of Environment, Sustainability, and Society at large (PO7, PO12).\n",
      "5.\tOrganize a good number of the add-on and modular courses by industry experts to realize the exposure to modern tool usage and solving of complex problems (PO4, PO5).\n",
      "6.\tIntroduce extension activities thorough NSS, NCC etc., to inculcate social consciousness and to build ethics among the students (PO6 & PO8).\n",
      "7.\tEncourage students to participate in global coding competitions and online certification courses (PO4, PO5).\n",
      "8.\tIntensive coaching for Civils, GRE aspirants in the campus itself (PO6, PO12)\n",
      "9.\tOrganize various E-Cell activities, SAAC activities and by introducing the Management Courses to impart managerial skills and leadership qualities (PO11, PO12).\n",
      "10.\tMandate three mids\n",
      "11.\tRise mandate attendance from 75% to 80%.\n",
      "12.\tIntroduce continuous assessment both in theory and laboratory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\sample5.txt\",\"r\",encoding='cp1252')\n",
    "file1= file.read()\n",
    "print(file1)\n",
    "#print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "url = \"C://Users//Ashu//Desktop//Project//sample5//sample5.txt\"\n",
    "url2 = \"C://Users//Ashu//Desktop//Project//sample5//lowercase.txt\"\n",
    "new_file = open(url2, 'w')\n",
    "with open(url, 'r') as fileinput:\n",
    "    for line in fileinput:\n",
    "        #line1=line.read()\n",
    "        line2 = line.lower()\n",
    "        new_file.write(line2)\n",
    "        #print(new_file)\n",
    "        #print(line2)\n",
    "new_file.close()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "#for i in range(1,1535):\n",
    "url = \"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\lowercase.txt\"\n",
    "url2 = \"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\specialchar.txt\"\n",
    "new_file = open(url2, 'w')\n",
    "remove = dict.fromkeys(map(ord,string.punctuation))\n",
    "with open(url,\"r\") as inputfile:\n",
    "    f = inputfile.read().translate(remove)\n",
    "    new_file.write(str(f))\n",
    "new_file.close()\n",
    "        #print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ashu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Ashu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ashu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "class Splitter(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.splitter = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        self.tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "\n",
    "    def split(self,text):\n",
    "        sentences = self.splitter.tokenize(text)\n",
    "        tokens = [self.tokenizer.tokenize(sent) for sent in sentences]\n",
    "        return tokens\n",
    "\n",
    "\n",
    "class LemmatizationWithPOSTagger(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def get_wordnet_pos(self,treebank_tag):\n",
    "        \n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            # As default pos in lemmatization is Noun\n",
    "            return wordnet.NOUN\n",
    "\n",
    "    def pos_tag(self,tokens):\n",
    "        \n",
    "        pos_tokens = [nltk.pos_tag(token) for token in tokens]\n",
    "\n",
    "        for pos in pos_tokens:       \n",
    "            pos_tokens =  [(lemmatizer.lemmatize(word,self.get_wordnet_pos(pos_tag))) for (word,pos_tag) in pos] \n",
    "            join = \" \".join(pos_tokens)\n",
    "        return join\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "splitter = Splitter()\n",
    "lemmatization_using_pos_tagger = LemmatizationWithPOSTagger()\n",
    "#for i in range(1,1535):\n",
    "url = \"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\specialchar.txt\"\n",
    "url1 = \"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\lemmatization1.txt\"\n",
    "newfile = open(url1,\"w\")\n",
    "with open(url, \"r\") as f:\n",
    "    file = f.read()\n",
    "    tokens = splitter.split(file)\n",
    "    lemma_pos_token = lemmatization_using_pos_tagger.pos_tag(tokens)\n",
    "    newfile.write(lemma_pos_token)\n",
    "new_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ashu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize\n",
    "#word_tokenize accepts a string as an input, not a file.\n",
    "#for i\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "url = \"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\lemmatization1.txt\"\n",
    "url2 = \"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\stopwords.txt\"\n",
    "file1 = open(url,\"r\")\n",
    "line = file1.read()# Use this to read file content as a stream:\n",
    "words = line.split()\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "for r in words:\n",
    "    if not r in stop_words:\n",
    "        appendFile = open(url2,'a')\n",
    "        appendFile.write(\" \"+r)\n",
    "        appendFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_complete = []\n",
    "#for i in range(1,1948):\n",
    "url = open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\stopwords.txt\", 'r')\n",
    "paragraph = url.read()\n",
    "file1=[paragraph]\n",
    "#print(file1)\n",
    "#doc_complete = doc_complete.append(paragraph)\n",
    "#print(paragraph)\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in doc.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in file1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['minute',\n",
       "  'department',\n",
       "  'advisory',\n",
       "  'committee',\n",
       "  'meet',\n",
       "  'hold',\n",
       "  '15122016',\n",
       "  'department',\n",
       "  'advisory',\n",
       "  'committee',\n",
       "  'meeting',\n",
       "  'department',\n",
       "  'computer',\n",
       "  'science',\n",
       "  'engineering',\n",
       "  'hold',\n",
       "  '15122016',\n",
       "  '1000',\n",
       "  'hodâ€™s',\n",
       "  'cabin',\n",
       "  'ii',\n",
       "  'floor',\n",
       "  'jcblock',\n",
       "  'dr',\n",
       "  'venkatesulu',\n",
       "  'dondeti',\n",
       "  'head',\n",
       "  'cse',\n",
       "  'chair',\n",
       "  'meeting',\n",
       "  'follow',\n",
       "  'member',\n",
       "  'attend',\n",
       "  'meeting',\n",
       "  'member',\n",
       "  'designation',\n",
       "  'signature',\n",
       "  '1',\n",
       "  'dr',\n",
       "  'venkatesulu',\n",
       "  'dondeti',\n",
       "  'professor',\n",
       "  'hod',\n",
       "  'chairman',\n",
       "  '2',\n",
       "  'dr',\n",
       "  'gnaneswara',\n",
       "  'rao',\n",
       "  'professor',\n",
       "  'member',\n",
       "  '3',\n",
       "  'dr',\n",
       "  'k',\n",
       "  'hemanth',\n",
       "  'kumar',\n",
       "  'professor',\n",
       "  'member',\n",
       "  '4',\n",
       "  'mr',\n",
       "  'v',\n",
       "  'rama',\n",
       "  'krishna',\n",
       "  'asst',\n",
       "  'professor',\n",
       "  'member',\n",
       "  'accord',\n",
       "  'feedback',\n",
       "  'give',\n",
       "  'stake',\n",
       "  'holder',\n",
       "  'thorough',\n",
       "  'analysis',\n",
       "  'consolidate',\n",
       "  'following',\n",
       "  'resolution',\n",
       "  'make',\n",
       "  'agenda',\n",
       "  'meeting',\n",
       "  '1',\n",
       "  'discussion',\n",
       "  'stakeholder',\n",
       "  'feedback',\n",
       "  'r13',\n",
       "  'r16',\n",
       "  'curriculum',\n",
       "  '2',\n",
       "  'discussion',\n",
       "  'co',\n",
       "  'po',\n",
       "  'attainment',\n",
       "  'outcome',\n",
       "  '3',\n",
       "  'action',\n",
       "  'initiate',\n",
       "  'address',\n",
       "  'noncompliance',\n",
       "  'curriculum',\n",
       "  'po',\n",
       "  'minute',\n",
       "  'meeting',\n",
       "  '1',\n",
       "  'dr',\n",
       "  'venkatesulu',\n",
       "  'chair',\n",
       "  'meeting',\n",
       "  'inform',\n",
       "  'per',\n",
       "  'stakeholder',\n",
       "  'feedback',\n",
       "  'old',\n",
       "  'curriculum',\n",
       "  'need',\n",
       "  'revision',\n",
       "  'new',\n",
       "  'curriculum',\n",
       "  'ug',\n",
       "  'program',\n",
       "  'propose',\n",
       "  '2',\n",
       "  'committee',\n",
       "  'member',\n",
       "  'discus',\n",
       "  'feedback',\n",
       "  'give',\n",
       "  'various',\n",
       "  'stakeholder',\n",
       "  '3',\n",
       "  'committee',\n",
       "  'member',\n",
       "  'discus',\n",
       "  'introduce',\n",
       "  'following',\n",
       "  'po',\n",
       "  'action',\n",
       "  'suggest',\n",
       "  'committee',\n",
       "  'member',\n",
       "  'bridge',\n",
       "  'gap',\n",
       "  'curriculum',\n",
       "  'po',\n",
       "  '4',\n",
       "  'co',\n",
       "  'attainment',\n",
       "  'report',\n",
       "  'committee',\n",
       "  'conclude',\n",
       "  'among',\n",
       "  'course',\n",
       "  'course',\n",
       "  'map',\n",
       "  'substantial',\n",
       "  'correlation',\n",
       "  'program',\n",
       "  'outcome',\n",
       "  'engineering',\n",
       "  'knowledge',\n",
       "  'po1',\n",
       "  'problem',\n",
       "  'analysis',\n",
       "  'po2',\n",
       "  'design',\n",
       "  'development',\n",
       "  'solution',\n",
       "  'po3',\n",
       "  'individual',\n",
       "  'team',\n",
       "  'work',\n",
       "  'po9',\n",
       "  'communication',\n",
       "  'po10',\n",
       "  'life',\n",
       "  'long',\n",
       "  'learning',\n",
       "  'po12',\n",
       "  'remain',\n",
       "  'program',\n",
       "  'outcome',\n",
       "  'conduct',\n",
       "  'investigation',\n",
       "  'complex',\n",
       "  'problem',\n",
       "  'po4',\n",
       "  'modern',\n",
       "  'tool',\n",
       "  'usage',\n",
       "  'po5',\n",
       "  'engineer',\n",
       "  'society',\n",
       "  'po6',\n",
       "  'environment',\n",
       "  'sustainability',\n",
       "  'po7',\n",
       "  'ethic',\n",
       "  'po8',\n",
       "  'project',\n",
       "  'management',\n",
       "  'finance',\n",
       "  'po11',\n",
       "  'moderate',\n",
       "  'correlation',\n",
       "  'suggestion',\n",
       "  '1',\n",
       "  'consistent',\n",
       "  'upgradation',\n",
       "  'course',\n",
       "  'curriculum',\n",
       "  'inline',\n",
       "  'industry',\n",
       "  'society',\n",
       "  'need',\n",
       "  '2',\n",
       "  'integrate',\n",
       "  'course',\n",
       "  'laboratory',\n",
       "  'minor',\n",
       "  'project',\n",
       "  'enrich',\n",
       "  'problemsolving',\n",
       "  'skill',\n",
       "  '3',\n",
       "  'involve',\n",
       "  'industry',\n",
       "  'research',\n",
       "  'personnel',\n",
       "  'course',\n",
       "  'curriculum',\n",
       "  'development',\n",
       "  'course',\n",
       "  'evaluation',\n",
       "  'feedback',\n",
       "  'enhance',\n",
       "  'quality',\n",
       "  'curriculum',\n",
       "  '4',\n",
       "  'inclusion',\n",
       "  'employability',\n",
       "  'life',\n",
       "  'skill',\n",
       "  'extension',\n",
       "  'activity',\n",
       "  'garden',\n",
       "  'yoga',\n",
       "  'etc',\n",
       "  'credit',\n",
       "  'course',\n",
       "  'realize',\n",
       "  'need',\n",
       "  'environment',\n",
       "  'sustainability',\n",
       "  'society',\n",
       "  'large',\n",
       "  'po7',\n",
       "  'po12',\n",
       "  '5',\n",
       "  'organize',\n",
       "  'good',\n",
       "  'number',\n",
       "  'addon',\n",
       "  'modular',\n",
       "  'course',\n",
       "  'industry',\n",
       "  'expert',\n",
       "  'realize',\n",
       "  'exposure',\n",
       "  'modern',\n",
       "  'tool',\n",
       "  'usage',\n",
       "  'solving',\n",
       "  'complex',\n",
       "  'problem',\n",
       "  'po4',\n",
       "  'po5',\n",
       "  '6',\n",
       "  'introduce',\n",
       "  'extension',\n",
       "  'activity',\n",
       "  'thorough',\n",
       "  'n',\n",
       "  'ncc',\n",
       "  'etc',\n",
       "  'inculcate',\n",
       "  'social',\n",
       "  'consciousness',\n",
       "  'build',\n",
       "  'ethic',\n",
       "  'among',\n",
       "  'student',\n",
       "  'po6',\n",
       "  'po8',\n",
       "  '7',\n",
       "  'encourage',\n",
       "  'student',\n",
       "  'participate',\n",
       "  'global',\n",
       "  'coding',\n",
       "  'competition',\n",
       "  'online',\n",
       "  'certification',\n",
       "  'course',\n",
       "  'po4',\n",
       "  'po5',\n",
       "  '8',\n",
       "  'intensive',\n",
       "  'coach',\n",
       "  'civils',\n",
       "  'gre',\n",
       "  'aspirant',\n",
       "  'campus',\n",
       "  'po6',\n",
       "  'po12',\n",
       "  '9',\n",
       "  'organize',\n",
       "  'various',\n",
       "  'ecell',\n",
       "  'activity',\n",
       "  'saac',\n",
       "  'activity',\n",
       "  'introduce',\n",
       "  'management',\n",
       "  'course',\n",
       "  'impart',\n",
       "  'managerial',\n",
       "  'skill',\n",
       "  'leadership',\n",
       "  'quality',\n",
       "  'po11',\n",
       "  'po12',\n",
       "  '10',\n",
       "  'mandate',\n",
       "  'three',\n",
       "  'mids',\n",
       "  '11',\n",
       "  'rise',\n",
       "  'mandate',\n",
       "  'attendance',\n",
       "  '75',\n",
       "  '80',\n",
       "  '12',\n",
       "  'introduce',\n",
       "  'continuous',\n",
       "  'assessment',\n",
       "  'theory',\n",
       "  'laboratory']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. dictionary = corpora.Dictionary(doc_clean)\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 4),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 2),\n",
       "  (6, 4),\n",
       "  (7, 4),\n",
       "  (8, 3),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 2),\n",
       "  (18, 4),\n",
       "  (19, 1),\n",
       "  (20, 1),\n",
       "  (21, 2),\n",
       "  (22, 1),\n",
       "  (23, 2),\n",
       "  (24, 2),\n",
       "  (25, 1),\n",
       "  (26, 1),\n",
       "  (27, 1),\n",
       "  (28, 2),\n",
       "  (29, 1),\n",
       "  (30, 1),\n",
       "  (31, 1),\n",
       "  (32, 1),\n",
       "  (33, 1),\n",
       "  (34, 1),\n",
       "  (35, 1),\n",
       "  (36, 2),\n",
       "  (37, 1),\n",
       "  (38, 1),\n",
       "  (39, 2),\n",
       "  (40, 1),\n",
       "  (41, 1),\n",
       "  (42, 6),\n",
       "  (43, 1),\n",
       "  (44, 1),\n",
       "  (45, 2),\n",
       "  (46, 1),\n",
       "  (47, 1),\n",
       "  (48, 1),\n",
       "  (49, 1),\n",
       "  (50, 1),\n",
       "  (51, 1),\n",
       "  (52, 1),\n",
       "  (53, 2),\n",
       "  (54, 10),\n",
       "  (55, 1),\n",
       "  (56, 1),\n",
       "  (57, 8),\n",
       "  (58, 3),\n",
       "  (59, 1),\n",
       "  (60, 1),\n",
       "  (61, 2),\n",
       "  (62, 2),\n",
       "  (63, 2),\n",
       "  (64, 2),\n",
       "  (65, 5),\n",
       "  (66, 1),\n",
       "  (67, 1),\n",
       "  (68, 1),\n",
       "  (69, 1),\n",
       "  (70, 2),\n",
       "  (71, 1),\n",
       "  (72, 1),\n",
       "  (73, 2),\n",
       "  (74, 2),\n",
       "  (75, 2),\n",
       "  (76, 1),\n",
       "  (77, 1),\n",
       "  (78, 1),\n",
       "  (79, 2),\n",
       "  (80, 5),\n",
       "  (81, 1),\n",
       "  (82, 1),\n",
       "  (83, 1),\n",
       "  (84, 2),\n",
       "  (85, 1),\n",
       "  (86, 1),\n",
       "  (87, 2),\n",
       "  (88, 1),\n",
       "  (89, 1),\n",
       "  (90, 1),\n",
       "  (91, 1),\n",
       "  (92, 1),\n",
       "  (93, 1),\n",
       "  (94, 1),\n",
       "  (95, 1),\n",
       "  (96, 2),\n",
       "  (97, 1),\n",
       "  (98, 1),\n",
       "  (99, 1),\n",
       "  (100, 1),\n",
       "  (101, 1),\n",
       "  (102, 1),\n",
       "  (103, 3),\n",
       "  (104, 1),\n",
       "  (105, 1),\n",
       "  (106, 1),\n",
       "  (107, 1),\n",
       "  (108, 1),\n",
       "  (109, 4),\n",
       "  (110, 1),\n",
       "  (111, 1),\n",
       "  (112, 1),\n",
       "  (113, 1),\n",
       "  (114, 1),\n",
       "  (115, 1),\n",
       "  (116, 1),\n",
       "  (117, 2),\n",
       "  (118, 1),\n",
       "  (119, 1),\n",
       "  (120, 1),\n",
       "  (121, 2),\n",
       "  (122, 1),\n",
       "  (123, 1),\n",
       "  (124, 2),\n",
       "  (125, 1),\n",
       "  (126, 2),\n",
       "  (127, 1),\n",
       "  (128, 1),\n",
       "  (129, 6),\n",
       "  (130, 8),\n",
       "  (131, 1),\n",
       "  (132, 1),\n",
       "  (133, 2),\n",
       "  (134, 1),\n",
       "  (135, 2),\n",
       "  (136, 1),\n",
       "  (137, 1),\n",
       "  (138, 1),\n",
       "  (139, 1),\n",
       "  (140, 3),\n",
       "  (141, 1),\n",
       "  (142, 1),\n",
       "  (143, 1),\n",
       "  (144, 1),\n",
       "  (145, 1),\n",
       "  (146, 2),\n",
       "  (147, 3),\n",
       "  (148, 1),\n",
       "  (149, 1),\n",
       "  (150, 1),\n",
       "  (151, 4),\n",
       "  (152, 1),\n",
       "  (153, 1),\n",
       "  (154, 2),\n",
       "  (155, 4),\n",
       "  (156, 1),\n",
       "  (157, 1),\n",
       "  (158, 3),\n",
       "  (159, 3),\n",
       "  (160, 3),\n",
       "  (161, 2),\n",
       "  (162, 2),\n",
       "  (163, 1),\n",
       "  (164, 3),\n",
       "  (165, 1),\n",
       "  (166, 4),\n",
       "  (167, 3),\n",
       "  (168, 2),\n",
       "  (169, 1),\n",
       "  (170, 2),\n",
       "  (171, 1),\n",
       "  (172, 1),\n",
       "  (173, 1),\n",
       "  (174, 1),\n",
       "  (175, 2),\n",
       "  (176, 1),\n",
       "  (177, 1),\n",
       "  (178, 1),\n",
       "  (179, 1),\n",
       "  (180, 1),\n",
       "  (181, 1),\n",
       "  (182, 1),\n",
       "  (183, 1),\n",
       "  (184, 1),\n",
       "  (185, 3),\n",
       "  (186, 1),\n",
       "  (187, 3),\n",
       "  (188, 1),\n",
       "  (189, 1),\n",
       "  (190, 1),\n",
       "  (191, 3),\n",
       "  (192, 2),\n",
       "  (193, 1),\n",
       "  (194, 1),\n",
       "  (195, 1),\n",
       "  (196, 2),\n",
       "  (197, 1),\n",
       "  (198, 1),\n",
       "  (199, 2),\n",
       "  (200, 1),\n",
       "  (201, 2),\n",
       "  (202, 1),\n",
       "  (203, 1),\n",
       "  (204, 2),\n",
       "  (205, 1),\n",
       "  (206, 2),\n",
       "  (207, 3),\n",
       "  (208, 1),\n",
       "  (209, 1)]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=2, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.023*\"course\" + 0.019*\"curriculum\" + 0.019*\"member\" + 0.014*\"meeting\" + 0.014*\"committee\" + 0.012*\"feedback\" + 0.012*\"dr\" + 0.010*\"introduce\" + 0.010*\"1\" + 0.010*\"3\"'), (1, '0.005*\"member\" + 0.005*\"course\" + 0.005*\"curriculum\" + 0.005*\"committee\" + 0.005*\"dr\" + 0.005*\"feedback\" + 0.005*\"meeting\" + 0.005*\"activity\" + 0.005*\"2\" + 0.005*\"professor\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=2, num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.023*\"course\" + 0.019*\"curriculum\" + 0.019*\"member\" + 0.014*\"meeting\" + 0.014*\"committee\" + 0.012*\"feedback\" + 0.012*\"dr\" + 0.010*\"introduce\" + 0.010*\"1\" + 0.010*\"3\"'), (1, '0.005*\"member\" + 0.005*\"course\" + 0.005*\"curriculum\" + 0.005*\"committee\" + 0.005*\"dr\" + 0.005*\"feedback\" + 0.005*\"meeting\" + 0.005*\"activity\" + 0.005*\"2\" + 0.005*\"professor\"')]\n",
      "<_io.TextIOWrapper name='C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\lda1.txt' mode='w' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "list1 = []\n",
    "f=open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\lda1.txt\",'w')\n",
    "list2 =(ldamodel.print_topics(num_topics=2, num_words=10))\n",
    "#print(list2)\n",
    "list2=str(list2)\n",
    "print(list2)\n",
    "f.write(list2)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course\n",
      "\n",
      "curriculum\n",
      "\n",
      "member\n",
      "\n",
      "meeting\n",
      "\n",
      "committee\n",
      "\n",
      "feedback\n",
      "\n",
      "dr\n",
      "\n",
      "introduce\n",
      "\n",
      "activity\n",
      "\n",
      "professor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\result5.csv\",'r') as in_file, open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\result51.csv\",'w',encoding=\"utf-8\") as out_file:\n",
    "    seen = set() # set for fast O(1) amortized lookup\n",
    "    for line in in_file:\n",
    "        if line in seen: continue # skip duplicate\n",
    "        print(line)\n",
    "        seen.add(line)\n",
    "        out_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'course': 6, 'curriculum': 4, 'member': 4, 'meeting': 3, 'committee': 3, 'feedback': 4, 'dr': 1}\n"
     ]
    }
   ],
   "source": [
    "accu_1 = {}\n",
    "data = open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\sample5.txt\",\"r\")\n",
    "file = data.read()\n",
    "\n",
    "word_data = open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\result51.csv\", 'r')\n",
    "data = word_data.read()\n",
    "words = data.split(\"\\n\")\n",
    "words.remove('')\n",
    "for i in words:\n",
    "    if i in file:\n",
    "        accu_1[i] = file.count(i)  \n",
    "print(accu_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINUTES OF THE DEPARTMENT ADVISORY COMMITTEE\n",
      "MEETING HELD ON 15.12.2016\n",
      "\t\tThe Department Advisory Committee Meeting of Department of Computer Science & Engineering was held on 15-12-2016 at 10:00 AM in the HoDâ€™s Cabin, II Floor, and JC-Block. Dr. Venkatesulu Dondeti, Head, CSE has chaired the s5word4 and the following s5word3s have attended the s5word4.\n",
      "S. No\tMembers\tDesignation\tSignature\n",
      "1\tDr. Venkatesulu  Dondeti\n",
      " \tProfessor & HOD \tChairman\t\n",
      "2\tDr. Gnaneswara Rao\n",
      "\tProfessor\tMember\t\n",
      "3\tDr. K. Hemanth Kumar,  Professor\tMember\t\n",
      "4\tMr. S. V. Rama Krishna, Asst. Professor\tMember\t\n",
      "\t\t\t\n",
      "According to the s5word6 given by stake holders and after thorough analysis, it is consolidated and following resolutions are made.\n",
      "Agenda of the Meeting:\n",
      "\n",
      "1. Discussion on stakeholder s5word6 on R13 & R16 Curriculum\n",
      "2. Discussion on CO & PO attainment outcomes\n",
      "3. Actions to be initiated to ads5word7ess the noncompliance of Curriculum with POs \n",
      "\n",
      "Minutes of the Meeting:\n",
      "1. Dr. Venkatesulu, Chair of the s5word4 has informed that, as per the stakeholder's s5word6 old s5word2 need revision and new s5word2  of UG  program should be proposed. \n",
      "\n",
      "2. The s5word5 s5word3s have discussed on the s5word6 given by various stakeholders\n",
      "\n",
      "3. The s5word5 s5word3s discussed by introducing the few of the following POs. Few actions were suggested by s5word5 s5word3s to bridge the gap between Curriculum and POs.\n",
      "\n",
      "4. From the CO & attainment report, the Committee concluded that among all the s5word1s, some s5word1s mapping with substantial correlation with Program Outcomes such as Engineering Knowledge (PO1), Problem Analysis (PO2), Design/ Development of Solutions (PO3), Individual and Team Work (PO9), Communications (PO10), Life Long Learning (PO12) and the remaining Program Outcomes such as Conduct Investigations of Complex Problems (PO4), Modern Tool Usage (PO5), The Engineer & Society (PO6), Environment and Sustainability (PO7), Ethics (PO8), Project Management and Finance (PO11) with moderate correlation.\n",
      "\n",
      "\n",
      "\n",
      "Suggestions:\n",
      "\n",
      "1.\tConsistent up-gradation of the s5word1 s5word2 in-line with the industry and society needs.\n",
      "2.\tIntegrate the s5word1s with laboratories and minor projects to enrich problem-solving skills.\n",
      "3.\tInvolve the Industry and Research personnel in Course Curriculum Development, Course Evaluation, and Feedback to enhance the quality of the s5word2.\n",
      "4.\tInclusion of Employability and Life Skills (Extension Activities, Gardening, Yoga, etc.) as Credit Courses to realize the needs of Environment, Sustainability, and Society at large (PO7, PO12).\n",
      "5.\tOrganize a good number of the add-on and modular s5word1s by industry experts to realize the exposure to modern tool usage and solving of complex problems (PO4, PO5).\n",
      "6.\tIntroduce extension activities thorough NSS, NCC etc., to inculcate social consciousness and to build ethics among the students (PO6 & PO8).\n",
      "7.\tEncourage students to participate in global coding competitions and online certification s5word1s (PO4, PO5).\n",
      "8.\tIntensive coaching for Civils, GRE aspirants in the campus itself (PO6, PO12)\n",
      "9.\tOrganize various E-Cell activities, SAAC activities and by introducing the Management Courses to impart managerial skills and leadership qualities (PO11, PO12).\n",
      "10.\tMandate three mids\n",
      "11.\tRise mandate attendance from 75% to 80%.\n",
      "12.\tIntroduce continuous assessment both in theory and laboratory.\n",
      "\n",
      "Time Consumed :  0.12094306945800781\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "x=[]\n",
    "y=[]\n",
    "with open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\result51.csv\", 'r') as filehandle:  \n",
    "    filecontents = filehandle.readlines()\n",
    "    for line in filecontents:\n",
    "        current_place = line[:-1]\n",
    "        x.append(current_place)\n",
    "\n",
    "with open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\Dictionary1.txt\", 'r') as filehandle:  \n",
    "    filecontents = filehandle.readlines()\n",
    "    for line in filecontents:\n",
    "        current_place = line[:-1]\n",
    "        y.append(current_place)\n",
    "\n",
    "s = open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\sample5.txt\").read()\n",
    "for i in range(len(x)):\n",
    "    s = s.replace(x[i],y[i])\n",
    "    f = open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\sample5.txt\", 'w')\n",
    "    f.write(s)\n",
    "    f.close()\n",
    "print(s)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Time Consumed : \",elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINUTES OF THE DEPARTMENT ADVISORY COMMITTEE\n",
      "MEETING HELD ON 15.12.2016\n",
      "\t\tThe Department Advisory Committee Meeting of Department of Computer Science & Engineering was held on 15-12-2016 at 10:00 AM in the HoDâ€™s Cabin, II Floor, and JC-Block. Dr. Venkatesulu Dondeti, Head, CSE has chaired the meeting and the following members have attended the meeting.\n",
      "S. No\tMembers\tDesignation\tSignature\n",
      "1\tDr. Venkatesulu  Dondeti\n",
      " \tProfessor & HOD \tChairman\t\n",
      "2\tDr. Gnaneswara Rao\n",
      "\tProfessor\tMember\t\n",
      "3\tDr. K. Hemanth Kumar,  Professor\tMember\t\n",
      "4\tMr. S. V. Rama Krishna, Asst. Professor\tMember\t\n",
      "\t\t\t\n",
      "According to the feedback given by stake holders and after thorough analysis, it is consolidated and following resolutions are made.\n",
      "Agenda of the Meeting:\n",
      "\n",
      "1. Discussion on stakeholder feedback on R13 & R16 Curriculum\n",
      "2. Discussion on CO & PO attainment outcomes\n",
      "3. Actions to be initiated to address the noncompliance of Curriculum with POs \n",
      "\n",
      "Minutes of the Meeting:\n",
      "1. Dr. Venkatesulu, Chair of the meeting has informed that, as per the stakeholder's feedback old curriculum need revision and new curriculum  of UG  program should be proposed. \n",
      "\n",
      "2. The committee members have discussed on the feedback given by various stakeholders\n",
      "\n",
      "3. The committee members discussed by introducing the few of the following POs. Few actions were suggested by committee members to bridge the gap between Curriculum and POs.\n",
      "\n",
      "4. From the CO & attainment report, the Committee concluded that among all the courses, some courses mapping with substantial correlation with Program Outcomes such as Engineering Knowledge (PO1), Problem Analysis (PO2), Design/ Development of Solutions (PO3), Individual and Team Work (PO9), Communications (PO10), Life Long Learning (PO12) and the remaining Program Outcomes such as Conduct Investigations of Complex Problems (PO4), Modern Tool Usage (PO5), The Engineer & Society (PO6), Environment and Sustainability (PO7), Ethics (PO8), Project Management and Finance (PO11) with moderate correlation.\n",
      "\n",
      "\n",
      "\n",
      "Suggestions:\n",
      "\n",
      "1.\tConsistent up-gradation of the course curriculum in-line with the industry and society needs.\n",
      "2.\tIntegrate the courses with laboratories and minor projects to enrich problem-solving skills.\n",
      "3.\tInvolve the Industry and Research personnel in Course Curriculum Development, Course Evaluation, and Feedback to enhance the quality of the curriculum.\n",
      "4.\tInclusion of Employability and Life Skills (Extension Activities, Gardening, Yoga, etc.) as Credit Courses to realize the needs of Environment, Sustainability, and Society at large (PO7, PO12).\n",
      "5.\tOrganize a good number of the add-on and modular courses by industry experts to realize the exposure to modern tool usage and solving of complex problems (PO4, PO5).\n",
      "6.\tIntroduce extension activities thorough NSS, NCC etc., to inculcate social consciousness and to build ethics among the students (PO6 & PO8).\n",
      "7.\tEncourage students to participate in global coding competitions and online certification courses (PO4, PO5).\n",
      "8.\tIntensive coaching for Civils, GRE aspirants in the campus itself (PO6, PO12)\n",
      "9.\tOrganize various E-Cell activities, SAAC activities and by introducing the Management Courses to impart managerial skills and leadership qualities (PO11, PO12).\n",
      "10.\tMandate three mids\n",
      "11.\tRise mandate attendance from 75% to 80%.\n",
      "12.\tIntroduce continuous assessment both in theory and laboratory.\n",
      "\n",
      "Time Consumed :  0.01699066162109375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "x=[]\n",
    "y=[]\n",
    "with open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\result51.csv\", 'r') as filehandle:  \n",
    "    filecontents = filehandle.readlines()\n",
    "    for line in filecontents:\n",
    "        current_place = line[:-1]\n",
    "        x.append(current_place)\n",
    "\n",
    "with open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\Dictionary1.txt\", 'r') as filehandle:  \n",
    "    filecontents = filehandle.readlines()\n",
    "    for line in filecontents:\n",
    "        current_place = line[:-1]\n",
    "        y.append(current_place)\n",
    "\n",
    "s = open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\sample5.txt\").read()\n",
    "for i in range(len(x)):\n",
    "    s = s.replace(y[i],x[i])\n",
    "    f = open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\sample5.txt\", 'w')\n",
    "    f.write(s)\n",
    "    f.close()\n",
    "print(s)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Time Consumed : \",elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu_2 = {}\n",
    "data = open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\sample5.txt\",\"r\")\n",
    "file = data.read()\n",
    "\n",
    "word_data = open(\"C:\\\\Users\\\\Ashu\\\\Desktop\\\\Project\\\\sample5\\\\result51.csv\", 'r')\n",
    "data = word_data.read()\n",
    "words = data.split(\"\\n\")\n",
    "words.remove('')\n",
    "for i in words:\n",
    "    if i in file:\n",
    "        accu_2[i] = file.count(i)  \n",
    "print(accu_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
